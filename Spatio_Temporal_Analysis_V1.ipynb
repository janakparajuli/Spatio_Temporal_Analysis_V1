{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0539cff9-a5ec-4998-9b7c-a147699ed328",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install required packages here\n",
    "#!pip install imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f49c1a-543b-4a97-9cf4-f519fdff808d",
   "metadata": {},
   "source": [
    "### ConvLSTM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaca469f-688d-458d-841a-ea4ffea61e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization, Conv3D\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b07ae876-4b0a-4650-8e77-1d54bf6a2597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGG_DAY_PERIOD</th>\n",
       "      <th>BOUNDS</th>\n",
       "      <th>CENTROID_LAT</th>\n",
       "      <th>CENTROID_LON</th>\n",
       "      <th>MEAN_ACTIVITY_INDEX_TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>(5.873565673828125, 51.04053042130972, 5.87493...</td>\n",
       "      <td>51.040962</td>\n",
       "      <td>5.874252</td>\n",
       "      <td>0.018629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>(5.87493896484375, 51.02844005602988, 5.876312...</td>\n",
       "      <td>51.028872</td>\n",
       "      <td>5.875626</td>\n",
       "      <td>0.164530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>(5.876312255859375, 51.03103111414404, 5.87768...</td>\n",
       "      <td>51.031463</td>\n",
       "      <td>5.876999</td>\n",
       "      <td>0.203132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>(5.876312255859375, 51.04053042130972, 5.87768...</td>\n",
       "      <td>51.040962</td>\n",
       "      <td>5.876999</td>\n",
       "      <td>0.233522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>(5.876312255859375, 51.04139389812637, 5.87768...</td>\n",
       "      <td>51.041826</td>\n",
       "      <td>5.876999</td>\n",
       "      <td>0.009507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AGG_DAY_PERIOD                                             BOUNDS  \\\n",
       "0     2020-01-20  (5.873565673828125, 51.04053042130972, 5.87493...   \n",
       "1     2020-01-20  (5.87493896484375, 51.02844005602988, 5.876312...   \n",
       "2     2020-01-20  (5.876312255859375, 51.03103111414404, 5.87768...   \n",
       "3     2020-01-20  (5.876312255859375, 51.04053042130972, 5.87768...   \n",
       "4     2020-01-20  (5.876312255859375, 51.04139389812637, 5.87768...   \n",
       "\n",
       "   CENTROID_LAT  CENTROID_LON  MEAN_ACTIVITY_INDEX_TOTAL  \n",
       "0     51.040962      5.874252                   0.018629  \n",
       "1     51.028872      5.875626                   0.164530  \n",
       "2     51.031463      5.876999                   0.203132  \n",
       "3     51.040962      5.876999                   0.233522  \n",
       "4     51.041826      5.876999                   0.009507  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(r\"./csv/Bounds_HAI.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1709132-7d94-4ff8-a4a8-eb37647e275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date field to datetime\n",
    "df['AGG_DAY_PERIOD'] = pd.to_datetime(df['AGG_DAY_PERIOD'])\n",
    "\n",
    "# Normalize the MEAN_ACTIVITY_INDEX_TOTAL\n",
    "scaler = MinMaxScaler()\n",
    "df['MEAN_ACTIVITY_INDEX_TOTAL'] = scaler.fit_transform(df[['MEAN_ACTIVITY_INDEX_TOTAL']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7ff167-8f5e-49cf-9ed0-41144a977a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequence of data for the model\n",
    "sequence_length = 10  # Define the sequence length\n",
    "sequences = []\n",
    "for i in range(len(data) - sequence_length):\n",
    "    sequences.append(data.iloc[i:i + sequence_length])\n",
    "\n",
    "# Convert the list of sequences to a NumPy array\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "train_data, test_data = train_test_split(sequences, test_size=0.2, shuffle=False)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5480c771-8354-4e74-848a-f8a0b8557a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for ConvLSTM\n",
    "def prepare_data(data):\n",
    "    X = []\n",
    "    y = []\n",
    "    for sequence in data:\n",
    "        X.append(sequence[['CENTROID_LAT', 'CENTROID_LON', 'MEAN_ACTIVITY_INDEX_TOTAL']].values)\n",
    "        y.append(sequence[-1]['MEAN_ACTIVITY_INDEX_TOTAL'])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1, X.shape[2], 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ce25106-e076-417c-a983-fa34d6ce76b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_data(train_data)\n",
    "X_val, y_val = prepare_data(val_data)\n",
    "X_test, y_test = prepare_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d459dff2-fe5e-49cb-86d3-89f04b4034bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84252114-02ad-4872-a826-0dcc26549fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161ef0b-72cf-46b9-ab9f-20a89d127d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982c7801-3813-47dd-a56d-8c60becb574f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece02640-c73e-4d14-bb12-eac15f7bc6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c094e146-f23f-403d-8e58-fb3792a35afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization, Conv3D\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import imageio\n",
    "\n",
    "# Load the CSV data\n",
    "data = pd.read_csv('Bounds_Hai.csv')\n",
    "\n",
    "# Convert date field to datetime\n",
    "data['AGG_DAY_PERIOD'] = pd.to_datetime(data['AGG_DAY_PERIOD'])\n",
    "\n",
    "# Normalize the MEAN_ACTIVITY_INDEX_TOTAL\n",
    "scaler = MinMaxScaler()\n",
    "data['MEAN_ACTIVITY_INDEX_TOTAL'] = scaler.fit_transform(data[['MEAN_ACTIVITY_INDEX_TOTAL']])\n",
    "\n",
    "# Create a sequence of data for the model\n",
    "sequence_length = 10  # Define the sequence length\n",
    "sequences = []\n",
    "for i in range(len(data) - sequence_length):\n",
    "    sequences.append(data.iloc[i:i + sequence_length])\n",
    "\n",
    "# Convert the list of sequences to a NumPy array\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "train_data, test_data = train_test_split(sequences, test_size=0.2, shuffle=False)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.25, shuffle=False)\n",
    "\n",
    "# Prepare the data for ConvLSTM\n",
    "def prepare_data(data):\n",
    "    X = []\n",
    "    y = []\n",
    "    for sequence in data:\n",
    "        X.append(sequence[['CENTROID_LAT', 'CENTROID_LON', 'MEAN_ACTIVITY_INDEX_TOTAL']].values)\n",
    "        y.append(sequence[-1]['MEAN_ACTIVITY_INDEX_TOTAL'])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1, X.shape[2], 1))\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_val, y_val = prepare_data(val_data)\n",
    "X_test, y_test = prepare_data(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4df31e-e3f5-4f89-9999-8e4e9994ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the ConvLSTM model\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(1, 3), input_shape=(sequence_length, 1, 3, 1), padding='same', return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(1, 3), padding='same', return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(1, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv3D(filters=1, kernel_size=(1, 1, 1), activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ddd39e-b434-49b9-aa3c-cbe7a9be1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683260c5-fbac-4a4c-975f-6d0800383e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random CSV file\n",
    "random_data = {\n",
    "    'AGG_DAY_PERIOD': pd.date_range(start='2021-01-01', periods=100),\n",
    "    'CENTROID_LAT': np.random.uniform(low=-90, high=90, size=100),\n",
    "    'CENTROID_LON': np.random.uniform(low=-180, high=180, size=100),\n",
    "    'MEAN_ACTIVITY_INDEX_TOTAL': np.random.uniform(low=0, high=1, size=100)\n",
    "}\n",
    "random_df = pd.DataFrame(random_data)\n",
    "random_df.to_csv('random_data.csv', index=False)\n",
    "\n",
    "# Preprocess the random data\n",
    "random_sequences = []\n",
    "for i in range(len(random_df) - sequence_length):\n",
    "    random_sequences.append(random_df.iloc[i:i + sequence_length])\n",
    "\n",
    "random_sequences = np.array(random_sequences)\n",
    "X_random, _ = prepare_data(random_sequences)\n",
    "\n",
    "# Predict using the trained model\n",
    "predictions = model.predict(X_random)\n",
    "\n",
    "# Rescale the predictions back to original scale\n",
    "predictions_rescaled = scaler.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Save the predictions to CSV\n",
    "prediction_dates = random_df['AGG_DAY_PERIOD'][sequence_length:].reset_index(drop=True)\n",
    "prediction_results = pd.DataFrame({'Date': prediction_dates, 'Predicted_Activity_Index': predictions_rescaled})\n",
    "prediction_results.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc3087-3330-4c52-a804-4523bfe81f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions as a shapefile\n",
    "gdf = gpd.GeoDataFrame(prediction_results, geometry=gpd.points_from_xy(random_df['CENTROID_LON'][sequence_length:], random_df['CENTROID_LAT'][sequence_length:]))\n",
    "gdf.to_file('predictions.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528ae272-85fb-409c-ba5e-5cca242743ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate animated map of the predictions\n",
    "images = []\n",
    "dates = prediction_results['Date'].unique()\n",
    "for date in dates:\n",
    "    daily_data = prediction_results[prediction_results['Date'] == date]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(daily_data['geometry'].x, daily_data['geometry'].y, c=daily_data['Predicted_Activity_Index'], cmap='viridis')\n",
    "    plt.colorbar(label='Predicted Activity Index')\n",
    "    plt.title(f'Predicted Activity Index on {date.date()}')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.savefig(f'map_{date.date()}.png')\n",
    "    images.append(imageio.imread(f'map_{date.date()}.png'))\n",
    "    plt.close()\n",
    "\n",
    "imageio.mimsave('predictions_animation.gif', images, duration=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39190d70-49a8-4c8e-b4b3-7d67712d89cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c2100-8ae1-4b15-adcd-7993a65b7e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57cc19-aba5-476a-bcad-606c20e26ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b21328c-6fe7-4fd4-a078-708b7302385f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
